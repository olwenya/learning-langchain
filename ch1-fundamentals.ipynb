{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436ca559-f09e-416a-8460-277e40c0182d",
   "metadata": {},
   "source": [
    "Message sent from the perspective of a human, using the `HumanMessage` interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80c70f6-ef02-4b0d-bdcd-d592dbd4a565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 14, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BLu8LhXO34UxlrshmHvIXI9BWQVdk', 'finish_reason': 'stop', 'logprobs': None}, id='run-13b39adc-247d-4ecb-a742-ecc44ac41c6d-0', usage_metadata={'input_tokens': 14, 'output_tokens': 8, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = [HumanMessage(\"What is the capital of France?\")]\n",
    "\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea05ba-3ba3-47f7-8ebe-73e64e5cf194",
   "metadata": {},
   "source": [
    "## Adding a System Message\n",
    "Using the `SystemMessage` interface to set instructions that the AI should follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee47189-aa5b-4efc-90c1-3ddaf3bc04e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Paris!!!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 35, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BLu8McVTavfoGNIMWZ7KAP1C02D1e', 'finish_reason': 'stop', 'logprobs': None}, id='run-9bf80c1a-93c2-4c45-bdc1-65fa4d915044-0', usage_metadata={'input_tokens': 35, 'output_tokens': 3, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "system_msg = SystemMessage('''\n",
    "You are a helpful assistant that responds to questions with a three exclamation marks.''')\n",
    "\n",
    "human_msg = prompt[0]\n",
    "\n",
    "model.invoke([system_msg, human_msg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2bccbd-dcf1-4745-a504-6c11725ed1c6",
   "metadata": {},
   "source": [
    "## Prompt templates\n",
    "Using `ChatPromptTemplate` to make prompts reusable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da98c69d-93f9-4647-9ad8-e5b54d48587e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital city of Kenya is Nairobi.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 70, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BLu8MJDTP1ghWR9WmkIFEUAD2gOZJ', 'finish_reason': 'stop', 'logprobs': None}, id='run-7698b484-f98c-466b-a709-8a3f30d337d8-0', usage_metadata={'input_tokens': 70, 'output_tokens': 9, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', '''Answer the question based on the context below. If the question cannot be answered using the\n",
    "        information provided, answer with \"I do not know\".'''),\n",
    "    ('human', 'Context: {context}'),\n",
    "    ('human', 'Question: {question}'),\n",
    "])\n",
    "prompt = template.invoke({\n",
    "    \"context\": 'a capital city is usually where the government of a region is located',\n",
    "    'question': 'What is the capital city of Kenya?'\n",
    "})\n",
    "\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6755f9be-1fe7-4752-8fb8-ba7852931e4c",
   "metadata": {},
   "source": [
    "## defining the output format\n",
    "Output can be configured, common ones being json, csv etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a743a800-c101-4963-8a77-587d7679167c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/unr3liable/.local/share/virtualenvs/learning-langchain-XCSQtIIB/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1637: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnswerWithJustification(answer='They weigh the same.', justification='Both a pound of bricks and a pound of feathers weigh one pound. The weight is the same, but the volume and density of the two substances differ.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    answer: str\n",
    "    '''The answer to the question'''\n",
    "    justification: str\n",
    "    '''Justification for the answer'''\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo' , temperature=0)\n",
    "structured_llm = llm.with_structured_output(AnswerWithJustification)\n",
    "structured_llm.invoke('''What weighs more, a pound of bricks or a pound of feathers?''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d202aa2-440d-4585-9536-dbc51aca159e",
   "metadata": {},
   "source": [
    "## Common interface\n",
    "- invoke: transform a single nput into an output\n",
    "- batch: transform multiple inputs, into multiple outputs\n",
    "- stream: streams output as they become available\n",
    "\n",
    "__Bonus__: you can decorate any function using `@chain` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "967ea6a1-6581-499c-90fd-8f4eed145c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Model providers like Lionel LLC, MTH Electric Trains, and Kato USA offer an array of LLMs (Limited Liability Models) for train enthusiasts and collectors. These models are typically based on real-life trains and often come in limited edition releases.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 25, 'total_tokens': 77, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BLu8OWBf6VnWESNMB9GqiSwMV2lZN', 'finish_reason': 'stop', 'logprobs': None}, id='run-3a7c820f-70c3-4194-b172-c8fd2d19ac6d-0', usage_metadata={'input_tokens': 25, 'output_tokens': 52, 'total_tokens': 77, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful assistant.'),\n",
    "    ('human', '{question}'),\n",
    "])\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    return model.invoke(prompt)\n",
    "\n",
    "chatbot.invoke({\"question\": \"which model providers offer LLMs?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d7879-71bc-4fbe-a54e-8c0c898f2c2d",
   "metadata": {},
   "source": [
    "### example using streams\n",
    "augment the chatbot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d99b6e-a9e0-4e85-99f0-76d41b892bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={} response_metadata={} id='run-0fe05ef6-b047-4ad1-9805-55b10b0dfa14'\n",
      "content='The' additional_kwargs={} response_metadata={} id='run-0fe05ef6-b047-4ad1-9805-55b10b0dfa14'\n",
      "content=' capital' additional_kwargs={} response_metadata={} id='run-0fe05ef6-b047-4ad1-9805-55b10b0dfa14'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run-0fe05ef6-b047-4ad1-9805-55b10b0dfa14'\n",
      "content=' Kenya' additional_kwargs={} response_metadata={} id='run-0fe05ef6-b047-4ad1-9805-55b10b0dfa14'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='run-0fe05ef6-b047-4ad1-9805-55b10b0dfa14'\n",
      "content=' Nairobi' additional_kwargs={} response_metadata={} id='run-0fe05ef6-b047-4ad1-9805-55b10b0dfa14'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-0fe05ef6-b047-4ad1-9805-55b10b0dfa14'\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'} id='run-0fe05ef6-b047-4ad1-9805-55b10b0dfa14'\n"
     ]
    }
   ],
   "source": [
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    for token in model.stream(prompt):\n",
    "        yield token\n",
    "\n",
    "for part in chatbot.stream({\n",
    "    'question': \"What is the capital of Kenya?\"\n",
    "}):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698b5058-35eb-4a31-a0a7-a1615dd6ff20",
   "metadata": {},
   "source": [
    "## LCEL (LangChain Expression Language)\n",
    "declarative language that optimizes execution plan (similar to apache spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37056c8a-11a6-481a-9774-5a900fdb6f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content='The' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' gest' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content='ation' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' period' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' an' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' elephant' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' approximately' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' ' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content='22' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' months' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' which' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' one' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' longest' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' gest' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content='ation' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' periods' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' among' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content=' mammals' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'} id='run-ece8a32d-ee45-4cc9-80cb-2557e96a3210'\n"
     ]
    }
   ],
   "source": [
    "chatbot = template | model\n",
    "\n",
    "for part in chatbot.stream({\n",
    "    'question': 'What is the gestation period for an elephant?'\n",
    "}):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bace8a7-d3f2-448e-9dd3-8b4be7941675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-langchain",
   "language": "python",
   "name": "learning-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
